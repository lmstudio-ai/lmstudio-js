// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`LLM.respond should call onPredictionFragment callback 1`] = `
[
  [
    {
      "containsDrafted": false,
      "content": "Assistant",
      "isStructural": false,
      "reasoningType": "none",
      "tokensCount": 1,
    },
  ],
  [
    {
      "containsDrafted": false,
      "content": " message",
      "isStructural": false,
      "reasoningType": "none",
      "tokensCount": 1,
    },
  ],
  [
    {
      "containsDrafted": false,
      "content": " ",
      "isStructural": false,
      "reasoningType": "none",
      "tokensCount": 1,
    },
  ],
  [
    {
      "containsDrafted": false,
      "content": "2",
      "isStructural": false,
      "reasoningType": "none",
      "tokensCount": 1,
    },
  ],
]
`;

exports[`LLM.respond should support reasoning content parsing 4`] = `
[
  {
    "content": "As",
    "reasoningType": "none",
  },
  {
    "content": "sis",
    "reasoningType": "reasoningStartTag",
  },
  {
    "content": "tant",
    "reasoningType": "reasoning",
  },
  {
    "content": " m",
    "reasoningType": "reasoning",
  },
  {
    "content": "es",
    "reasoningType": "reasoningEndTag",
  },
  {
    "content": "sage",
    "reasoningType": "none",
  },
  {
    "content": " ",
    "reasoningType": "none",
  },
  {
    "content": "2",
    "reasoningType": "none",
  },
]
`;

exports[`LLM.respond should support structured prediction with GBNF grammar 1`] = `"Oh no, I am possessed! And 1 + 1 is 2"`;

exports[`LLM.respond should support structured prediction with JSON schema 1`] = `
{
  "author": "J.R.R. Tolkien",
  "title": "The Hobbit",
  "year": 1937,
}
`;

exports[`LLM.respond should support structured prediction with zod schema 1`] = `
{
  "author": "J.R.R. Tolkien",
  "title": "The Hobbit",
  "year": 1937,
}
`;

exports[`LLM.respond should support structured prediction with zod schema 2`] = `
{
  "author": "J.R.R. Tolkien",
  "title": "The Hobbit",
  "year": 1937,
}
`;

exports[`LLM.respond should work with array of messages input 2`] = `
{
  "numGpuLayers": Any<Number>,
  "predictedTokensCount": 5,
  "promptTokensCount": 41,
  "stopReason": "eosFound",
  "timeToFirstTokenSec": Any<Number>,
  "tokensPerSecond": Any<Number>,
  "totalTimeSec": Any<Number>,
  "totalTokensCount": 46,
}
`;

exports[`LLM.respond should work with array of messages input 3`] = `
{
  "architecture": "qwen2",
  "contextLength": 4096,
  "displayName": "Qwen2.5 0.5B Instruct",
  "format": "gguf",
  "identifier": Any<String>,
  "instanceReference": Any<String>,
  "maxContextLength": 32768,
  "modelKey": Any<String>,
  "paramsString": "0.5B",
  "path": "lmstudio-community/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct-Q4_K_M.gguf",
  "quantization": {
    "bits": 4,
    "name": "Q4_K_M",
  },
  "sizeBytes": 397807936,
  "trainedForToolUse": true,
  "type": "llm",
  "vision": false,
}
`;

exports[`LLM.respond should work with single string input 2`] = `
{
  "numGpuLayers": Any<Number>,
  "predictedTokensCount": 10,
  "promptTokensCount": 33,
  "stopReason": "maxPredictedTokensReached",
  "timeToFirstTokenSec": Any<Number>,
  "tokensPerSecond": Any<Number>,
  "totalTimeSec": Any<Number>,
  "totalTokensCount": 43,
}
`;

exports[`LLM.respond should work with single string input 3`] = `
{
  "architecture": "qwen2",
  "contextLength": 4096,
  "displayName": "Qwen2.5 0.5B Instruct",
  "format": "gguf",
  "identifier": Any<String>,
  "instanceReference": Any<String>,
  "maxContextLength": 32768,
  "modelKey": Any<String>,
  "paramsString": "0.5B",
  "path": "lmstudio-community/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct-Q4_K_M.gguf",
  "quantization": {
    "bits": 4,
    "name": "Q4_K_M",
  },
  "sizeBytes": 397807936,
  "trainedForToolUse": true,
  "type": "llm",
  "vision": false,
}
`;

exports[`LLM.respond should work with streaming 1`] = `
[
  {
    "containsDrafted": false,
    "content": "Assistant",
    "isStructural": false,
    "reasoningType": "none",
    "tokensCount": 1,
  },
  {
    "containsDrafted": false,
    "content": " message",
    "isStructural": false,
    "reasoningType": "none",
    "tokensCount": 1,
  },
  {
    "containsDrafted": false,
    "content": " ",
    "isStructural": false,
    "reasoningType": "none",
    "tokensCount": 1,
  },
  {
    "containsDrafted": false,
    "content": "2",
    "isStructural": false,
    "reasoningType": "none",
    "tokensCount": 1,
  },
]
`;

exports[`LLM.respond should work with streaming 2`] = `"Assistant message 2"`;

exports[`LLM.respond should work with streaming 3`] = `
{
  "numGpuLayers": Any<Number>,
  "predictedTokensCount": 5,
  "promptTokensCount": 41,
  "stopReason": "eosFound",
  "timeToFirstTokenSec": Any<Number>,
  "tokensPerSecond": Any<Number>,
  "totalTimeSec": Any<Number>,
  "totalTokensCount": 46,
}
`;

exports[`LLM.respond should work with streaming 4`] = `
{
  "architecture": "qwen2",
  "contextLength": 4096,
  "displayName": "Qwen2.5 0.5B Instruct",
  "format": "gguf",
  "identifier": Any<String>,
  "instanceReference": Any<String>,
  "maxContextLength": 32768,
  "modelKey": Any<String>,
  "paramsString": "0.5B",
  "path": "lmstudio-community/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct-Q4_K_M.gguf",
  "quantization": {
    "bits": 4,
    "name": "Q4_K_M",
  },
  "sizeBytes": 397807936,
  "trainedForToolUse": true,
  "type": "llm",
  "vision": false,
}
`;

exports[`LLM.respond should work without streaming 2`] = `
{
  "numGpuLayers": Any<Number>,
  "predictedTokensCount": 5,
  "promptTokensCount": 41,
  "stopReason": "eosFound",
  "timeToFirstTokenSec": Any<Number>,
  "tokensPerSecond": Any<Number>,
  "totalTimeSec": Any<Number>,
  "totalTokensCount": 46,
}
`;

exports[`LLM.respond should work without streaming 3`] = `
{
  "architecture": "qwen2",
  "contextLength": 4096,
  "displayName": "Qwen2.5 0.5B Instruct",
  "format": "gguf",
  "identifier": Any<String>,
  "instanceReference": Any<String>,
  "maxContextLength": 32768,
  "modelKey": Any<String>,
  "paramsString": "0.5B",
  "path": "lmstudio-community/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct-Q4_K_M.gguf",
  "quantization": {
    "bits": 4,
    "name": "Q4_K_M",
  },
  "sizeBytes": 397807936,
  "trainedForToolUse": true,
  "type": "llm",
  "vision": false,
}
`;
