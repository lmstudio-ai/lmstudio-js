// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`LLM Can tokenize correctly 1`] = `
[
  1143,
  64866,
  374,
  264,
  35765,
  13,
]
`;

exports[`LLM can apply prompt template to a regular chat 1`] = `
"<|im_start|>system
This is the system prompt.<|im_end|>
<|im_start|>user
User message 1<|im_end|>
<|im_start|>assistant
Assistant message 1<|im_end|>
<|im_start|>user
User message 2<|im_end|>
<|im_start|>assistant
"
`;

exports[`LLM can get model info 1`] = `
{
  "architecture": "qwen2",
  "contextLength": 4096,
  "displayName": "Qwen2.5 0.5B Instruct",
  "format": "gguf",
  "identifier": Any<String>,
  "instanceReference": Any<String>,
  "maxContextLength": 32768,
  "modelKey": Any<String>,
  "paramsString": "1B",
  "path": "lmstudio-community/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct-Q4_K_M.gguf",
  "sizeBytes": 397807936,
  "trainedForToolUse": true,
  "type": "llm",
  "vision": false,
}
`;
